{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaanch Lite - Full Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the simplified legal document intelligence pipeline:\n",
    "\n",
    "1. **Parse** - Landing AI ADE (grounded chunks with bounding boxes)\n",
    "2. **Embed** - Voyage AI voyage-law-2 (legal-specific embeddings)\n",
    "3. **Extract Citations** - Hybrid regex + Instructor/Pydantic\n",
    "4. **Verify Citations** - Against pre-indexed acts library\n",
    "5. **Search** - RAG with Voyage rerank-2.5 (instruction-following)\n",
    "\n",
    "## Comparison with Full Jaanch\n",
    "\n",
    "| Component | Full Jaanch | Jaanch Lite |\n",
    "|-----------|-------------|-------------|\n",
    "| Lines of Code | ~50,000 | ~1,000 |\n",
    "| Bbox Linking | 71 files | 0 (native from ADE) |\n",
    "| Embeddings | OpenAI ada-002 | Voyage voyage-law-2 |\n",
    "| Reranking | Cohere | Voyage rerank-2.5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies and configure API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "# !pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API keys are set\n",
    "assert os.getenv('VISION_AGENT_API_KEY'), \"Set VISION_AGENT_API_KEY in .env\"\n",
    "assert os.getenv('VOYAGE_API_KEY'), \"Set VOYAGE_API_KEY in .env\"\n",
    "assert os.getenv('OPENAI_API_KEY'), \"Set OPENAI_API_KEY in .env\"\n",
    "\n",
    "print(\"API keys configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parse Document with Landing AI ADE\n",
    "\n",
    "ADE provides:\n",
    "- OCR for scanned PDFs\n",
    "- Chunking with semantic boundaries\n",
    "- **Native bounding boxes** (no fuzzy matching!)\n",
    "- Table and figure extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.parsers.ade_parser import parse_document\n",
    "\n",
    "# Parse a sample document\n",
    "# Replace with your own legal document\n",
    "SAMPLE_PDF = Path(\"../data/samples/sample_legal_doc.pdf\")\n",
    "\n",
    "if SAMPLE_PDF.exists():\n",
    "    chunks = parse_document(\n",
    "        SAMPLE_PDF,\n",
    "        document_id=\"sample_doc\",\n",
    "        matter_id=\"demo_matter\"\n",
    "    )\n",
    "    print(f\"Parsed {len(chunks)} chunks\")\n",
    "else:\n",
    "    print(f\"Sample file not found: {SAMPLE_PDF}\")\n",
    "    print(\"Place a legal PDF in data/samples/ to test\")\n",
    "    chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine a chunk with visual grounding\n",
    "if chunks:\n",
    "    chunk = chunks[0]\n",
    "    print(f\"Chunk ID: {chunk.chunk_id}\")\n",
    "    print(f\"Page: {chunk.page}\")\n",
    "    print(f\"Type: {chunk.chunk_type}\")\n",
    "    print(f\"BBox: {chunk.bbox}\")\n",
    "    print(f\"\\nText preview:\\n{chunk.text[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Citations (Hybrid Regex + LLM)\n",
    "\n",
    "Two-stage extraction:\n",
    "1. **Fast regex** - catches ~80% of citations\n",
    "2. **LLM validation** - handles edge cases with Instructor/Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.citations.extractor import CitationExtractor\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = CitationExtractor(\n",
    "    use_llm=True,  # Set to False for regex-only mode\n",
    "    model=\"gpt-4o-mini\"  # Fast and cheap\n",
    ")\n",
    "\n",
    "# Test on sample text\n",
    "sample_text = \"\"\"\n",
    "The accused was charged under Section 302 of the Indian Penal Code, 1860 \n",
    "for murder. The prosecution also invoked Section 34 IPC for common intention.\n",
    "\n",
    "During the trial, the defense cited Article 21 of the Constitution regarding \n",
    "the right to fair trial. The court also considered Section 138 of the \n",
    "Negotiable Instruments Act, 1881 in relation to the dishonored cheque.\n",
    "\n",
    "Under u/s 420 of the Indian Penal Code, the accused was also charged with cheating.\n",
    "\"\"\"\n",
    "\n",
    "result = extractor.extract(sample_text)\n",
    "print(f\"Found {len(result.citations)} citations\\n\")\n",
    "\n",
    "for cit in result.citations:\n",
    "    print(f\"- Section {cit.section} of {cit.act_name}\")\n",
    "    print(f\"  Confidence: {cit.confidence:.2f}, Method: {cit.extraction_method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract from document chunks (with visual grounding)\n",
    "if chunks:\n",
    "    doc_citations = extractor.extract_from_chunks(chunks)\n",
    "    print(f\"Found {len(doc_citations.citations)} citations in document\\n\")\n",
    "    \n",
    "    for cit in doc_citations.citations[:5]:\n",
    "        print(f\"- S. {cit.section} {cit.act_name}\")\n",
    "        print(f\"  Page: {cit.source_page}, BBox: {cit.source_bbox}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Voyage AI Embeddings\n",
    "\n",
    "Using `voyage-law-2` - a legal-specific embedding model that understands:\n",
    "- Legal terminology\n",
    "- Citation formats\n",
    "- Statutory language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.embeddings.voyage import VoyageEmbedder\n",
    "\n",
    "# Initialize embedder\n",
    "embedder = VoyageEmbedder(model=\"voyage-law-2\")\n",
    "\n",
    "# Embed some legal texts\n",
    "texts = [\n",
    "    \"Section 138 of the Negotiable Instruments Act deals with dishonour of cheque\",\n",
    "    \"The accused was convicted under Section 302 IPC for murder\",\n",
    "    \"Article 21 guarantees the right to life and personal liberty\",\n",
    "]\n",
    "\n",
    "embeddings = embedder.embed_documents(texts)\n",
    "print(f\"Generated {len(embeddings)} embeddings\")\n",
    "print(f\"Embedding dimension: {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed a query\n",
    "query = \"What is the punishment for cheque bounce?\"\n",
    "query_embedding = embedder.embed_query(query)\n",
    "print(f\"Query embedding dimension: {len(query_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Voyage AI Reranking\n",
    "\n",
    "Using `rerank-2.5` with instruction-following capabilities.\n",
    "Can specify what type of legal documents to prioritize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.embeddings.voyage import VoyageReranker, LEGAL_RERANK_INSTRUCTIONS\n",
    "\n",
    "# Initialize reranker\n",
    "reranker = VoyageReranker(model=\"rerank-2.5\")\n",
    "\n",
    "# Sample documents to rerank\n",
    "documents = [\n",
    "    \"Section 138 of NI Act provides for punishment of imprisonment up to 2 years\",\n",
    "    \"In Kumar v. State, the court held that cheque bounce is a serious offense\",\n",
    "    \"The drawer of a dishonored cheque shall be deemed to have committed an offense\",\n",
    "    \"Legal commentary on Section 138 suggests strict liability\",\n",
    "    \"The Negotiable Instruments Act, 1881 was amended in 2015\",\n",
    "]\n",
    "\n",
    "query = \"What is the punishment for cheque bounce?\"\n",
    "\n",
    "# Rerank with instruction to prioritize statutes\n",
    "results = reranker.rerank(\n",
    "    query=query,\n",
    "    documents=documents,\n",
    "    top_k=3,\n",
    "    instruction=LEGAL_RERANK_INSTRUCTIONS[\"statutes\"]\n",
    ")\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Reranked results (prioritizing statutes):\\n\")\n",
    "for r in results:\n",
    "    print(f\"Score: {r['relevance_score']:.3f}\")\n",
    "    print(f\"Text: {r['document']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Acts Library\n",
    "\n",
    "Index Indian Central Acts for citation verification.\n",
    "This is a one-time setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.acts.indexer import ActsIndexer\n",
    "from src.acts.india_code import KNOWN_ACTS\n",
    "\n",
    "# Show known acts\n",
    "print(f\"Known acts: {len(KNOWN_ACTS)}\\n\")\n",
    "for act in KNOWN_ACTS[:5]:\n",
    "    print(f\"- {act['canonical_name']}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize acts indexer\n",
    "# Note: Run scripts/index_acts.py to build the full index\n",
    "acts_indexer = ActsIndexer()\n",
    "print(f\"Acts index stats: {acts_indexer.get_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify Citations\n",
    "\n",
    "Check if citations reference real sections in actual acts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.acts.verifier import ActsVerifier\n",
    "from src.core.models import Citation\n",
    "\n",
    "# Initialize verifier\n",
    "verifier = ActsVerifier()\n",
    "\n",
    "# Create a citation to verify\n",
    "citation = Citation(\n",
    "    act_name=\"Negotiable Instruments Act, 1881\",\n",
    "    section=\"138\",\n",
    "    raw_text=\"Section 138 of NI Act\",\n",
    "    confidence=0.9,\n",
    ")\n",
    "\n",
    "# Verify\n",
    "result = verifier.verify(citation)\n",
    "print(f\"Citation: S. {citation.section} of {citation.act_name}\")\n",
    "print(f\"Status: {result.status.value}\")\n",
    "print(f\"Similarity: {result.similarity_score:.2f if result.similarity_score else 'N/A'}\")\n",
    "if result.matched_text:\n",
    "    print(f\"\\nMatched text:\\n{result.matched_text[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Full RAG Search\n",
    "\n",
    "Combines:\n",
    "- ChromaDB vector store\n",
    "- Voyage embeddings\n",
    "- Voyage reranking\n",
    "- Visual grounding from ADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.search.rag import RAGSearch\n",
    "\n",
    "# Initialize RAG search\n",
    "rag = RAGSearch()\n",
    "\n",
    "# Add document chunks\n",
    "if chunks:\n",
    "    count = rag.add_document(chunks)\n",
    "    print(f\"Added {count} chunks to document store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with reranking\n",
    "if chunks:\n",
    "    query = \"What are the key legal issues?\"\n",
    "    \n",
    "    results = rag.search(\n",
    "        query=query,\n",
    "        matter_id=\"demo_matter\",\n",
    "        top_k=3,\n",
    "        rerank=True,\n",
    "        legal_category=\"statutes\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(f\"Results: {len(results.results)} (reranked: {results.reranked})\\n\")\n",
    "    \n",
    "    for r in results.results:\n",
    "        print(f\"--- Result #{r.rank} ---\")\n",
    "        print(f\"Page: {r.page}, Score: {r.score:.3f}\")\n",
    "        print(f\"BBox: {r.bbox}\")\n",
    "        print(f\"Text: {r.chunk.text[:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the Jaanch Lite pipeline:\n",
    "\n",
    "| Step | Component | What it does |\n",
    "|------|-----------|-------------|\n",
    "| 1 | Landing AI ADE | Parse PDF with native grounding |\n",
    "| 2 | Instructor/Pydantic | Extract citations with schema |\n",
    "| 3 | Voyage voyage-law-2 | Legal-specific embeddings |\n",
    "| 4 | Voyage rerank-2.5 | Instruction-following reranking |\n",
    "| 5 | ChromaDB | Vector storage |\n",
    "| 6 | Acts Library | Citation verification |\n",
    "\n",
    "**Total complexity: ~1,000 lines of code** (vs ~50,000 in full Jaanch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
